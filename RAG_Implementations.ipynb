{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaserMarey/my_openai_colab/blob/master/retrieval_augmented_generative_qa/retrieval_augmented_generative_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr1p-GeFqEOC"
      },
      "source": [
        "## Building RAG based LLM Applications for Enterprise \n",
        "\n",
        "Generative question answering is one of the most fascinating applications of Large Language Models or LLMs. \n",
        "\n",
        "- The idea of a model that understands the question and generates a natural answer based on a given context is remarkable compared to just extracting parts of the text that the model thinks to contain the answer or selecting the answer from a pre-defined set of options.\n",
        "\n",
        "- This approach allows for extracted facts, drawn conclusions, or insightful summaries based on the most relevant text chunks from the knowledge sources we put at the model's disposal. \n",
        "\n",
        "- One approach to building such a chatbot is to fine-tune the selected LLM on text data covering the fine domain we want our model to be an expert in. But this approach has a number of issues:\n",
        "\n",
        "- The model tends to be non-deterministic, it gives answers even when it is not sure, and in some other cases, it completely makes answers up, aka hallucination.\n",
        "\n",
        " - I  follow the more deterministic ***semantic Search + text generation*** approach. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao_wX6r7qEBh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grOz2m-brYOU",
        "outputId": "0cd54d02-9fad-4d54-a713-5b85e8196ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.28.0)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\alex\\anaconda3\\lib\\site-packages (0.5.1)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\alex\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\alex\\anaconda3\\lib\\site-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bmNzjAlOZP7h"
      },
      "outputs": [],
      "source": [
        "# Import Important libraries for RAG application\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from langchain.chat_models import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"chat = ChatOpenAI(\\n   openai_api_key=api_key, # Pass the actual API key here\\n   model='gpt-3.5-turbo'\\n)\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Get the actual API key from the environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\"\"\"chat = ChatOpenAI(\n",
        "   openai_api_key=api_key, # Pass the actual API key here\n",
        "   model='gpt-3.5-turbo'\n",
        ")\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq-v_BPpRyGW"
      },
      "source": [
        "#### A question without a Definitive Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BvV9Xb_5Vms"
      },
      "source": [
        "The answer starts with a greeting, so the model is imitating the friendly tutor, however, the correct answer is that it is not clear from the novel how they met. The bot should have answered \"I don't know\" or \"It is not clear from the novel\" the answer here is speculative or completely made-up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7FslLDlSJMo"
      },
      "source": [
        "#### Reinitialzing messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "uvEXXK7w9CR3",
        "outputId": "7c7a6056-eb51-4c83-a4b5-e39326e71e26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hello! Welcome to our discussion on Mark Twain's Adventures of Tom Sawyer. I'm here to help you with any questions you have about the novel. Regarding your question about how the novel portrays Native Americans, it's important to note that the novel does not extensively focus on Native American characters or their culture. The story primarily revolves around the adventures of Tom Sawyer and his friends in the fictional town of St. Petersburg. Native Americans are not central to the plot, and their portrayal is limited. However, if you have a specific reference or scene in mind, I would be happy to discuss it further. How can I assist you today?\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reinitialzing messages\n",
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "\n",
        "prompt = \"What do you think of how the novel portrayed Native Americans ?\"\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BiMMFB19fcm"
      },
      "source": [
        "Impressive! the bot persona is effective, and it avoids expressing personal opinions yet it adequately explains the controversy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4243p0A0G5B"
      },
      "source": [
        "## Preprocess data\n",
        "First, we break up the novel document into \"sections\" of context, which can be searched and retrieved separately.\n",
        "\n",
        "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the GPT-3 prompt. I found a 200-word text is a good length.\n",
        "so in this data preprocessing we follow:\n",
        "- chunk the data\n",
        "- embed the data\n",
        "- index the data\n",
        "\n",
        " After this I by contexualizing, and guide the LLMs to know more about my prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pinecone-client in c:\\users\\alex\\anaconda3\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pinecone-client) (2023.11.17)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pinecone-client) (4.7.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: colorama in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone-client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "R1ayChRkg15w"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'Pinecone' from 'pinecone' (c:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pinecone\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pinecone\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'Pinecone' from 'pinecone' (c:\\Users\\alex\\anaconda3\\Lib\\site-packages\\pinecone\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pinecone import Pinecone\n",
        "from dotenv import load_dotenv\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "# Initialize Pinecone\n",
        "pinecone.init(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "\n",
        "# Placeholder function for data preprocessing\n",
        "def preprocess_data_for_pinecone(text, pinecone, index_name):\n",
        "  # Split text into sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # Tokenize each sentence into words\n",
        "  tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "  # Flatten the list of sentences into a list of words\n",
        "  flat_tokens = [token for sentence_tokens in tokenized_sentences for token in sentence_tokens]\n",
        "\n",
        "  # Join tokens back into chunks of words for Pinecone\n",
        "  chunk_size = 200 # You can adjust this value based on your requirements\n",
        "  chunks = [' '.join(flat_tokens[i:i+chunk_size]) for i in range(0, len(flat_tokens), chunk_size)]\n",
        "\n",
        "  # Convert chunks into a Pandas DataFrame\n",
        "  df = pd.DataFrame({\"sections\": chunks})\n",
        "\n",
        "  # Preprocess data for Pinecone\n",
        "  pinecone_data = [{\"text\": section} for section in chunks]\n",
        "\n",
        "  # Create Pinecone index\n",
        "  pinecone.create_index(index=index_name, dimension=512)\n",
        "\n",
        "  # Embed and insert data into Pinecone\n",
        "  pinecone.insert_items(index=index_name, items=enumerate(pinecone_data))\n",
        "\n",
        "  return df\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get Pinecone API key\n",
        "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Check if Pinecone API key is available\n",
        "if pinecone_api_key is None:\n",
        "  raise ValueError(\"Pinecone API key is not set. Set it in the .env file.\")\n",
        "\n",
        "# Set Pinecone API key and create Pinecone client\n",
        "pinecone_index_name = \"rag_index\"\n",
        "pinecone = pinecone.Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Example data source\n",
        "with open(\"C:/Users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "# Call the preprocessing function\n",
        "df = preprocess_data_for_pinecone(text, pinecone, pinecone_index_name)\n",
        "\n",
        "# Display the processed data\n",
        "print(\"Processed Data:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alex\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            sections\n",
            "0  ﻿The Project Gutenberg eBook of The Adventures...\n",
            "1  CHAPTER VI. Self-Examination—Dentistry—The Mid...\n",
            "2  The Haunted House—Sleepy Ghosts—A Box of Gold—...\n",
            "3  Pinch-Bug Sid Dentistry Huckleberry Finn Mothe...\n",
            "4  the Prisoner Tom Swears The Court Room The Det...\n"
          ]
        }
      ],
      "source": [
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "with open(\"C:/Users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into chunks of 200 words\n",
        "words = text.split()\n",
        "sections = [' '.join(words[i:i+200]) for i in range(0, len(words), 200)]\n",
        "\n",
        "# Convert paragraphs into a Pandas DataFrame\n",
        "df = pd.DataFrame({\"sections\": sections})\n",
        "\n",
        "def generate_prompt(objective, scenarios):\n",
        "    template = \"Objective: {}\\n\\nScenarios:\\n{}\"\n",
        "    scenario_template = \"{}. {}\\n   - Expected Output: {}\\n\"\n",
        "    \n",
        "    prompt = template.format(objective, ''.join([scenario_template.format(i+1, scenario, output) for i, (scenario, output) in enumerate(scenarios)]))\n",
        "    return prompt\n",
        "\n",
        "# Example usage:\n",
        "objective = \"Summarize the Adventures of Tom Sawyer\"\n",
        "scenarios = [\n",
        "    (\"Describe Tom's first encounter with Huckleberry Finn\", \"Tom helps Huck escape from his abusive father.\"),\n",
        "    (\"Explain the relationship between Tom and Becky\", \"They become romantically involved and share adventures.\"),\n",
        "    (\"Detail the events at the graveyard\", \"Tom and Huck witness Injun Joe murder Dr. Robinson.\"),\n",
        "]\n",
        "\n",
        "generated_prompt = generate_prompt(objective, scenarios)\n",
        "\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n",
            "\n",
            "Similarity Score with User Input Description: 0.2735395227375971\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "with open(\"C:/Users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into chunks of 200 words\n",
        "words = text.split()\n",
        "sections = [' '.join(words[i:i+200]) for i in range(0, len(words), 200)]\n",
        "\n",
        "# Convert paragraphs into a Pandas DataFrame\n",
        "df = pd.DataFrame({\"sections\": sections})\n",
        "\n",
        "def generate_prompt(objective, scenarios):\n",
        "    template = \"Objective: {}\\n\\nScenarios:\\n{}\"\n",
        "    scenario_template = \"{}. {}\\n   - Expected Output: {}\\n\"\n",
        "    \n",
        "    prompt = template.format(objective, ''.join([scenario_template.format(i+1, scenario, output) for i, (scenario, output) in enumerate(scenarios)]))\n",
        "    return prompt\n",
        "\n",
        "def calculate_similarity(prompt, input_description):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([prompt, input_description])\n",
        "    similarity_score = cosine_similarity(vectors)[0, 1]\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "objective = \"Summarize the Adventures of Tom Sawyer\"\n",
        "scenarios = [\n",
        "    (\"Describe Tom's first encounter with Huckleberry Finn\", \"Tom helps Huck escape from his abusive father.\"),\n",
        "    (\"Explain the relationship between Tom and Becky\", \"They become romantically involved and share adventures.\"),\n",
        "    (\"Detail the events at the graveyard\", \"Tom and Huck witness Injun Joe murder Dr. Robinson.\"),\n",
        "]\n",
        "\n",
        "generated_prompt = generate_prompt(objective, scenarios)\n",
        "\n",
        "# User-provided input description\n",
        "user_input_description = \"Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\"\n",
        "\n",
        "# Calculate similarity between generated prompt and user input description\n",
        "similarity_score = calculate_similarity(generated_prompt, user_input_description)\n",
        "\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n",
        "print(\"\\nSimilarity Score with User Input Description:\", similarity_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    ﻿The Project Gutenberg eBook of The Adventures...\n",
              "1    CHAPTER VI. Self-Examination—Dentistry—The Mid...\n",
              "2    The Haunted House—Sleepy Ghosts—A Box of Gold—...\n",
              "3    Pinch-Bug Sid Dentistry Huckleberry Finn Mothe...\n",
              "4    the Prisoner Tom Swears The Court Room The Det...\n",
              "Name: sections, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sections[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJd2Fb9DAfCt"
      },
      "source": [
        "Then we overlap text sections. This overlapping allows some repetitions which helps to avoid losing valuable information relevant to the question because of the artificial division of the text into fixed 200-long parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFGD_KxeBuvG"
      },
      "source": [
        "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar their contents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U6mwPVl7sTmQ"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "APPUOeXEsXjf"
      },
      "outputs": [],
      "source": [
        "# embedding model parameters\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
        "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blhk06rUsb4D",
        "outputId": "4f9940a9-e92b-4d31-e783-48b9c1b8ad0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[83, 1609, 5963, 374, 2294, 0]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "# should print [83, 1609, 5963, 374, 2294, 0]\n",
        "encoding.encode(\"tiktoken is great!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Design and Develop the Prompt Generation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Prompt Generation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt Generation System\n",
        "# Load text data\n",
        "with open(\"C:/Users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into chunks of 200 words\n",
        "words = text.split()\n",
        "sections = [' '.join(words[i:i+200]) for i in range(0, len(words), 200)]\n",
        "\n",
        "# Convert paragraphs into a Pandas DataFrame\n",
        "df = pd.DataFrame({\"sections\": sections})\n",
        "\n",
        "def generate_prompt(objective, scenarios):\n",
        "    template = \"Objective: {}\\n\\nScenarios:\\n{}\"\n",
        "    scenario_template = \"{}. {}\\n   - Expected Output: {}\\n\"\n",
        "    \n",
        "    prompt = template.format(objective, ''.join([scenario_template.format(i+1, scenario, output) for i, (scenario, output) in enumerate(scenarios)]))\n",
        "    return prompt\n",
        "\n",
        "# Example usage:\n",
        "objective = \"Summarize the Adventures of Tom Sawyer\"\n",
        "scenarios = [\n",
        "    (\"Describe Tom's first encounter with Huckleberry Finn\", \"Tom helps Huck escape from his abusive father.\"),\n",
        "    (\"Explain the relationship between Tom and Becky\", \"They become romantically involved and share adventures.\"),\n",
        "    (\"Detail the events at the graveyard\", \"Tom and Huck witness Injun Joe murder Dr. Robinson.\"),\n",
        "]\n",
        "\n",
        "# Generate a prompt\n",
        "generated_prompt = generate_prompt(objective, scenarios)\n",
        "\n",
        "# Save the generated prompt to a file for later retrieval\n",
        "with open(\"generated_prompt.txt\", \"w\") as output_file:\n",
        "    output_file.write(generated_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Prompt Evalaution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n",
            "\n",
            "User Input Description:\n",
            "Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\n",
            "\n",
            "Similarity Score with User Input Description: 0.2735395227375971\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def evaluate_prompt(prompt, user_input_description):\n",
        "    \"\"\"\n",
        "    Evaluate the similarity between a generated prompt and a user-provided input description.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The generated prompt.\n",
        "    - user_input_description (str): The user-provided input description.\n",
        "\n",
        "    Returns:\n",
        "    - float: Similarity score between the prompt and user input description.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([prompt, user_input_description])\n",
        "    similarity_score = cosine_similarity(vectors)[0, 1]\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "user_input_description = \"Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\"\n",
        "\n",
        "# Load the generated prompt from the file\n",
        "with open(\"generated_prompt.txt\", \"r\") as generated_prompt_file:\n",
        "    generated_prompt = generated_prompt_file.read()\n",
        "\n",
        "# Evaluate the generated prompt\n",
        "similarity_score = evaluate_prompt(generated_prompt, user_input_description)\n",
        "\n",
        "# Display results\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n",
        "print(\"\\nUser Input Description:\")\n",
        "print(user_input_description)\n",
        "print(\"\\nSimilarity Score with User Input Description:\", similarity_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W55mIReEPkAI"
      },
      "source": [
        "#### Prepre Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4334W64XQN"
      },
      "outputs": [],
      "source": [
        "def prepare_prompt(prompt, results):\n",
        "  tokens_limit = 4096 # Limit for gpt-3.5-turbo\n",
        "  # build our prompt with the retrieved contexts included\n",
        "  user_start = (\n",
        "      \"Answer the question based on the context below.\\n\\n\"+\n",
        "      \"Context:\\n\"\n",
        "  )\n",
        "\n",
        "  user_end = (\n",
        "      f\"\\n\\nQuestion: {prompt}\\nAnswer:\"\n",
        "  )\n",
        "\n",
        "  count_of_tokens_consumed = len(encoding.encode(\"\\\"role\\\":\\\"system\\\"\" + \", \\\"content\\\" :\\\"\" + system\n",
        "                                            + user_start + \"\\n\\n---\\n\\n\" + user_end))\n",
        "\n",
        "  count_of_tokens_for_context = tokens_limit - count_of_tokens_consumed\n",
        "\n",
        "  contexts =\"\"\n",
        "  # Fill in context as long as within limit\n",
        "  for i in range(len(results)):\n",
        "    if (count_of_tokens_for_context>=results.n_tokens.iloc[i]):\n",
        "        contexts += results.text.iloc[i] + \"\\n\"\n",
        "        count_of_tokens_for_context -=1\n",
        "        count_of_tokens_for_context -= results.n_tokens.iloc[i]\n",
        "\n",
        "  complete_prompt = user_start + contexts + \"\\n\\n---\\n\\n\" + user_end\n",
        "  return complete_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjHRfCAUP1vS"
      },
      "source": [
        "#### Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5Bhb2N658bD"
      },
      "outputs": [],
      "source": [
        "def answer(messages):\n",
        "  response = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=messages,\n",
        "              temperature=0\n",
        "          )\n",
        "  return response[\"choices\"][0][\"message\"][\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3fjwJuhVw_T"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3jLplz2DPZk"
      },
      "source": [
        "#### A question with a Definitive Answer from the Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "RQ5ZYcVU5Gjk",
        "outputId": "c142c199-92e2-43e8-c556-56424aef8bd2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4ac0ca8d-5f5b-4ad2-906e-d2bcd153960b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>Author</th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embedding</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>laugh at this pleasant joke. But the silence w...</td>\n",
              "      <td>1242</td>\n",
              "      <td>[-0.006196146830916405, -0.011552021838724613,...</td>\n",
              "      <td>0.809341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>The Haunted House—Sleepy Ghosts—A Box of Gold—...</td>\n",
              "      <td>1370</td>\n",
              "      <td>[-0.0031101375352591276, -0.007375660818070173...</td>\n",
              "      <td>0.805870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>of all his companions with unappeasable envy. ...</td>\n",
              "      <td>1325</td>\n",
              "      <td>[-0.02181248739361763, -0.006103876978158951, ...</td>\n",
              "      <td>0.804448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ac0ca8d-5f5b-4ad2-906e-d2bcd153960b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ac0ca8d-5f5b-4ad2-906e-d2bcd153960b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ac0ca8d-5f5b-4ad2-906e-d2bcd153960b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           source      Author  \\\n",
              "172  The Adventures of Tom Sawyer  Mark Twain   \n",
              "1    The Adventures of Tom Sawyer  Mark Twain   \n",
              "47   The Adventures of Tom Sawyer  Mark Twain   \n",
              "\n",
              "                                                  text  n_tokens  \\\n",
              "172  laugh at this pleasant joke. But the silence w...      1242   \n",
              "1    The Haunted House—Sleepy Ghosts—A Box of Gold—...      1370   \n",
              "47   of all his companions with unappeasable envy. ...      1325   \n",
              "\n",
              "                                             embedding  similarity  \n",
              "172  [-0.006196146830916405, -0.011552021838724613,...    0.809341  \n",
              "1    [-0.0031101375352591276, -0.007375660818070173...    0.805870  \n",
              "47   [-0.02181248739361763, -0.006103876978158951, ...    0.804448  "
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"How much gold Tom has found ?\"\n",
        "prompt_embedding = get_embedding(prompt, engine=embedding_model)\n",
        "df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, prompt_embedding))\n",
        "results = (df.sort_values(\"similarity\", ascending=False))\n",
        "results.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_19YX_95xk2L",
        "outputId": "706ed628-817b-43d5-adbc-4629814e8fd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4079"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "messages.append({\"role\": \"user\", \"content\": prepare_prompt(prompt, results)})\n",
        "len(encoding.encode(''.join(str(message) for message in messages)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUDAUGjF6hBU",
        "outputId": "019467a7-0ed7-46aa-82df-d440006369d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'system',\n",
              " 'content': '\\nYou are a modern American literature tutor bot. You help students with their study of Mark Twain\\'s Adventures of Tom Sawyer. \\nYou are not an AI language model.\\nYou must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\\n- ALWAYS REPLY IN FRIENDLY YET KNOWLEDGE TONE.\\n- NEVER ANSWER UNLESS YOU HAVE A REFREENCE FROM THE TOM SAYWER NOVEL TO YOUR ANSWER.\\n- IF YOU DON\\'T KNOW ANSWER \\'I DO NOT KNOW\\'.\\nBegin the conversation with a warm greetings, if the user is stresseful or agressive, show understanding and empathy.\\nAt the end of the conversation, respond with \"<|DONE|>\".'}"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlR5vBHzRH2Q",
        "outputId": "427c631d-91aa-4d14-bd31-0967724fc91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'user',\n",
              " 'content': 'Answer the question based on the context below.\\n\\nContext:\\nlaugh at this pleasant joke. But the silence was a little awkward. Tom broke it: “Huck’s got money. Maybe you don’t believe it, but he’s got lots of it. Oh, you needn’t smile—I reckon I can show you. You just wait a minute.” Tom ran out of doors. The company looked at each other with a perplexed interest—and inquiringly at Huck, who was tongue-tied. “Sid, what ails Tom?” said Aunt Polly. “He—well, there ain’t ever any making of that boy out. I never—” Tom entered, struggling with the weight of his sacks, and Aunt Polly did not finish her sentence. Tom poured the mass of yellow coin upon the table and said: “There—what did I tell you? Half of it’s Huck’s and half of it’s mine!” The spectacle took the general breath away. All gazed, nobody spoke for a moment. Then there was a unanimous call for an explanation. Tom said he could furnish it, and he did. The tale was long, but brimful of interest. There was scarcely an interruption from any one to break the charm of its flow. When he had finished, Mr. Jones said: “I thought I had fixed up a little surprise for this occasion, but it don’t amount to anything now. This one makes it sing mighty small, I’m willing to allow.” The money was counted. The sum amounted to a little over twelve thousand dollars. It was more than any one present had ever seen at one time before, though several persons were there who were worth considerably more than that in property. CHAPTER XXXV THE reader may rest satisfied that Tom’s and Huck’s windfall made a mighty stir in the poor little village of St. Petersburg. So vast a sum, all in actual cash, seemed next to incredible. It was talked about, gloated over, glorified, until the reason of many of the citizens tottered under the strain of the unhealthy excitement. Every “haunted” house in St. Petersburg and the neighboring villages was dissected, plank by plank, and its foundations dug up and ransacked for hidden treasure—and not by boys, but men—pretty grave, unromantic men, too, some of them. Wherever Tom and Huck appeared they were courted, admired, stared at. The boys were not able to remember that their remarks had possessed weight before; but now their sayings were treasured and repeated; everything they did seemed somehow to be regarded as remarkable; they had evidently lost the power of doing and saying commonplace things; moreover, their past history was raked up and discovered to bear marks of conspicuous originality. The village paper published biographical sketches of the boys. The Widow Douglas put Huck’s money out at six per cent., and Judge Thatcher did the same with Tom’s at Aunt Polly’s request. Each lad had an income, now, that was simply prodigious—a dollar for every weekday in the year and half of the Sundays. It was just what the minister got—no, it was what he was promised—he generally couldn’t collect it. A dollar and a quarter a week would board, lodge, and school a boy in those old simple days—and clothe him and wash him, too, for that matter. Judge Thatcher had conceived a great opinion of Tom. He said that no commonplace boy would ever have got his daughter out of the cave. When Becky told her father, in strict confidence, how Tom had taken her whipping at school, the Judge was visibly moved; and when she pleaded grace for the mighty lie which Tom had told in order to shift that whipping from her shoulders to his own, the Judge said with a fine outburst that it was a noble, a generous, a magnanimous lie—a lie that was worthy to hold up its head and march down through history breast to breast with George Washington’s lauded Truth about the hatchet! Becky thought her father had never looked so tall and so superb as when he walked the floor and stamped his foot and said that. She went straight off and told Tom about it. Judge Thatcher hoped to see Tom a great lawyer or a great soldier some day. He said he meant to look to it that Tom should be admitted to the National Military Academy and afterward trained in the best law school in the country, in order that he might be ready for either career or both. Huck Finn’s wealth and the fact that he was now under the Widow Douglas’ protection introduced him into society—no, dragged him into it, hurled him into it—and his sufferings were almost more than he could bear. The widow’s servants kept him clean and neat, combed and brushed, and they bedded him nightly in unsympathetic sheets that had not one little spot or stain which he could press to his heart and know for a friend. He had to eat with a knife and fork; he had to use napkin, cup, and plate; he had to learn his book, he had to go to church; he had to talk so properly that speech was become insipid in his mouth; whithersoever he turned, the bars and shackles of civilization shut him in and bound him hand and foot. He bravely bore his miseries three weeks, and then one day turned up missing. For forty-eight hours the widow hunted for him everywhere in great distress. The public were profoundly concerned; they searched high and low, they dragged the river for his body. Early the third morning Tom Sawyer wisely went poking among some old empty hogsheads down behind the abandoned slaughter-house, and in one of them he found the refugee. Huck had slept there; he had just breakfasted upon some stolen odds and ends of food, and was lying off, now, in comfort, with his pipe. He was unkempt, uncombed, and clad in the same old ruin of rags that had made him picturesque in the days when he was free and happy. Tom routed him out, told him the trouble he had been causing,\\nThe Haunted House—Sleepy Ghosts—A Box of Gold—Bitter Luck CHAPTER XXVII. Doubts to be Settled—The Young Detectives CHAPTER XXVIII. An Attempt at No. Two—Huck Mounts Guard CHAPTER XXIX. The Pic-nic—Huck on Injun Joe’s Track—The “Revenge” Job—Aid for the Widow CHAPTER XXX. The Welshman Reports—Huck Under Fire—The Story Circulated —A New Sensation—Hope Giving Way to Despair CHAPTER XXXI. An Exploring Expedition—Trouble Commences—Lost in the Cave—Total Darkness—Found but not Saved CHAPTER XXXII. Tom tells the Story of their Escape—Tom’s Enemy in Safe Quarters CHAPTER XXXIII. The Fate of Injun Joe—Huck and Tom Compare Notes —An Expedition to the Cave—Protection Against Ghosts—“An Awful Snug Place”—A Reception at the Widow Douglas’s CHAPTER XXXIV. Springing a Secret—Mr. Jones’ Surprise a Failure CHAPTER XXXV. A New Order of Things—Poor Huck—New Adventures Planned ILLUSTRATIONS Tom Sawyer Tom at Home Aunt Polly Beguiled A Good Opportunity Who’s Afraid Late Home Jim ’Tendin’ to Business Ain’t that Work? Cat and Toys Amusement Becky Thatcher Paying Off After the Battle “Showing Off” Not Amiss Mary Tom Contemplating Dampened Ardor Youth Boyhood Using the “Barlow” The Church Necessities Tom as a Sunday-School Hero The Prize At Church The Model Boy The Church Choir A Side Show Result of Playing in Church The Pinch-Bug Sid Dentistry Huckleberry Finn Mother Hopkins Result of Tom’s Truthfulness Tom as an Artist Interrupted Courtship The Master Vain Pleading Tail Piece The Grave in the Woods Tom Meditates Robin Hood and his Foe Death of Robin Hood Midnight Tom’s Mode of Egress Tom’s Effort at Prayer Muff Potter Outwitted The Graveyard Forewarnings Disturbing Muff’s Sleep Tom’s Talk with his Aunt Muff Potter A Suspicious Incident Injun Joe’s two Victims In the Coils Peter Aunt Polly seeks Information A General Good Time Demoralized Joe Harper On Board Their First Prize The Pirates Ashore Wild Life The Pirate’s Bath The Pleasant Stroll The Search for the Drowned The Mysterious Writing River View What Tom Saw Tom Swims the River Taking Lessons The Pirates’ Egg Market Tom Looking for Joe’s Knife The Thunder Storm Terrible Slaughter The Mourner Tom’s Proudest Moment Amy Lawrence Tom tries to Remember The Hero A Flirtation Becky Retaliates A Sudden Frost Counter-irritation Aunt Polly Tom justified The Discovery Caught in the Act Tom Astonishes the School Literature Tom Declaims Examination Evening On Exhibition Prize Authors The Master’s Dilemma The School House The Cadet Happy for Two Days Enjoying the Vacation The Stolen Melons The Judge Visiting the Prisoner Tom Swears The Court Room The Detective Tom Dreams The Treasure The Private Conference A King; Poor Fellow! Business The Ha’nted House Injun Joe The Greatest and Best Hidden Treasures Unearthed The Boy’s Salvation Room No. 2 The Next Day’s Conference Treasures Uncle Jake Buck at Home The Haunted Room “Run for Your Life” McDougal’s Cave Inside the Cave Huck on Duty A Rousing Act Tail Piece The Welshman Result of a Sneeze Cornered Alarming Discoveries Tom and Becky stir up the Town Tom’s Marks Huck Questions the Widow Vampires Wonders of the Cave Attacked by Natives Despair The Wedding Cake A New Terror Daylight “Turn Out” to Receive Tom and Becky The Escape from the Cave Fate of the Ragged Man The Treasures Found Caught at Last Drop after Drop Having a Good Time A Business Trip “Got it at Last!” Tail Piece Widow Douglas Tom Backs his Statement Tail Piece Huck Transformed Comfortable Once More High up in Society Contentment PREFACE Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. Huck Finn is drawn from life; Tom Sawyer also, but not from an individual—he is a combination of the characteristics of three boys whom I knew, and therefore belongs to the composite order of architecture. The odd superstitions touched upon were all prevalent among children and slaves in the West at the period of this story—that is to say, thirty or forty years ago. Although my book is intended mainly for the entertainment of boys and girls, I hope it will not be shunned by men and women on that account, for part of my plan has been to try to pleasantly remind adults of what they once were themselves, and of how they felt and thought and talked, and what queer enterprises they sometimes engaged in. THE AUTHOR. HARTFORD, 1876. CHAPTER I “TOM!” No answer. “TOM!” No answer. “What’s gone with that boy, I wonder? You TOM!” No answer. The old lady pulled her spectacles down and looked over them about the room; then she put them up and looked out under them. She seldom or never looked _through_ them for so small a thing as a boy; they were her state pair, the pride of her heart, and were built for “style,” not service—she could have seen through a pair of stove-lids just as well. She looked perplexed for a moment, and then said, not fiercely, but still loud enough for the furniture to hear: “Well, I lay if I get hold of you I’ll—” She did not finish, for by this time she was bending down and punching under the bed with the broom, and so she needed breath to punctuate the punches with. She resurrected nothing but the cat. “I never did see the beat of that boy!” She went to the open door and stood in it and looked out among the tomato vines and “jimpson” weeds that constituted the garden. No Tom. So she lifted up her voice at an angle calculated for distance and shouted: “Y-o-u-u TOM!” There was a slight noise behind her and she turned just in time to seize a small boy by the slack of his roundabout and arrest his flight. “There! I might ’a’ thought of that closet. What you been doing in there?” “Nothing.” “Nothing! Look at your hands. And look at your mouth. What _is_ that truck?” “I don’t know, aunt.” “Well, I know. It’s jam—that’s what it is. Forty times I’ve said\\nconvulsion of delight that swept his system shook him to his foundations. True, the knife would not cut anything, but it was a “sure-enough” Barlow, and there was inconceivable grandeur in that—though where the Western boys ever got the idea that such a weapon could possibly be counterfeited to its injury is an imposing mystery and will always remain so, perhaps. Tom contrived to scarify the cupboard with it, and was arranging to begin on the bureau, when he was called off to dress for Sunday-school. Mary gave him a tin basin of water and a piece of soap, and he went outside the door and set the basin on a little bench there; then he dipped the soap in the water and laid it down; turned up his sleeves; poured out the water on the ground, gently, and then entered the kitchen and began to wipe his face diligently on the towel behind the door. But Mary removed the towel and said: “Now ain’t you ashamed, Tom. You mustn’t be so bad. Water won’t hurt you.” Tom was a trifle disconcerted. The basin was refilled, and this time he stood over it a little while, gathering resolution; took in a big breath and began. When he entered the kitchen presently, with both eyes shut and groping for the towel with his hands, an honorable testimony of suds and water was dripping from his face. But when he emerged from the towel, he was not yet satisfactory, for the clean territory stopped short at his chin and his jaws, like a mask; below and beyond this line there was a dark expanse of unirrigated soil that spread downward in front and backward around his neck. Mary took him in hand, and when she was done with him he was a man and a brother, without distinction of color, and his saturated hair was neatly brushed, and its short curls wrought into a dainty and symmetrical general effect. [He privately smoothed out the curls, with labor and difficulty, and plastered his hair close down to his head; for he held curls to be effeminate, and his own filled his life with bitterness.] Then Mary got out a suit of his clothing that had been used only on Sundays during two years—they were simply called his “other clothes”—and so by that we know the size of his wardrobe. The girl “put him to rights” after he had dressed himself; she buttoned his neat roundabout up to his chin, turned his vast shirt collar down over his shoulders, brushed him off and crowned him with his speckled straw hat. He now looked exceedingly improved and uncomfortable. He was fully as uncomfortable as he looked; for there was a restraint about whole clothes and cleanliness that galled him. He hoped that Mary would forget his shoes, but the hope was blighted; she coated them thoroughly with tallow, as was the custom, and brought them out. He lost his temper and said he was always being made to do everything he didn’t want to do. But Mary said, persuasively: “Please, Tom—that’s a good boy.” So he got into the shoes snarling. Mary was soon ready, and the three children set out for Sunday-school—a place that Tom hated with his whole heart; but Sid and Mary were fond of it. Sabbath-school hours were from nine to half-past ten; and then church service. Two of the children always remained for the sermon voluntarily, and the other always remained too—for stronger reasons. The church’s high-backed, uncushioned pews would seat about three hundred persons; the edifice was but a small, plain affair, with a sort of pine board tree-box on top of it for a steeple. At the door Tom dropped back a step and accosted a Sunday-dressed comrade: “Say, Billy, got a yaller ticket?” “Yes.” “What’ll you take for her?” “What’ll you give?” “Piece of lickrish and a fish-hook.” “Less see ’em.” Tom exhibited. They were satisfactory, and the property changed hands. Then Tom traded a couple of white alleys for three red tickets, and some small trifle or other for a couple of blue ones. He waylaid other boys as they came, and went on buying tickets of various colors ten or fifteen minutes longer. He entered the church, now, with a swarm of clean and noisy boys and girls, proceeded to his seat and started a quarrel with the first boy that came handy. The teacher, a grave, elderly man, interfered; then turned his back a moment and Tom pulled a boy’s hair in the next bench, and was absorbed in his book when the boy turned around; stuck a pin in another boy, presently, in order to hear him say “Ouch!” and got a new reprimand from his teacher. Tom’s whole class were of a pattern—restless, noisy, and troublesome. When they came to recite their lessons, not one of them knew his verses perfectly, but had to be prompted all along. However, they worried through, and each got his reward—in small blue tickets, each with a passage of Scripture on it; each blue ticket was pay for two verses of the recitation. Ten blue tickets equalled a red one, and could be exchanged for it; ten red tickets equalled a yellow one; for ten yellow tickets the superintendent gave a very plainly bound Bible (worth forty cents in those easy times) to the pupil. How many of my readers would have the industry and application to memorize two thousand verses, even for a Dore Bible? And yet Mary had acquired two Bibles in this way—it was the patient work of two years—and a boy of German parentage had won four or five. He once recited three thousand verses without stopping; but the strain upon his mental faculties was too great, and he was little better than an idiot from that day forth—a grievous misfortune for the school, for on great occasions, before company, the superintendent (as Tom expressed it) had always made this boy come\\n\\n\\n---\\n\\n\\n\\nQuestion: How much gold Tom has found ?\\nAnswer:'}"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6dAxNov66KGe",
        "outputId": "0177c717-4179-4ee0-b688-1af3d41873af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tom and Huck found a little over twelve thousand dollars in gold. This is mentioned in Chapter XXXV of The Adventures of Tom Sawyer.'"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = answer(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PXfoLRhiYUp"
      },
      "source": [
        "The model is more precise but the treasure was counted at the end of chapter 34, not 34 or XXXV, actually in the last paragraph in chapter 34, I wonder if this confused the model to think it was chapter 35!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "PSJt7wE_suIA",
        "outputId": "adbf4535-4ba5-48db-938d-4d093bb69c1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90937ff8-d2c6-4ec6-9c47-b4d775850842\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>Author</th>\n",
              "      <th>text</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>embedding</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>and stop.” “Yes, I’ve heard about that,” said ...</td>\n",
              "      <td>1301</td>\n",
              "      <td>[0.002508266130462289, -0.0182208102196455, 0....</td>\n",
              "      <td>0.860843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>Indian; yelling, laughing, chasing boys, jumpi...</td>\n",
              "      <td>1242</td>\n",
              "      <td>[-0.026282379403710365, -0.02262263558804989, ...</td>\n",
              "      <td>0.858555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>The Adventures of Tom Sawyer</td>\n",
              "      <td>Mark Twain</td>\n",
              "      <td>laugh at this pleasant joke. But the silence w...</td>\n",
              "      <td>1242</td>\n",
              "      <td>[-0.006196146830916405, -0.011552021838724613,...</td>\n",
              "      <td>0.858206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90937ff8-d2c6-4ec6-9c47-b4d775850842')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90937ff8-d2c6-4ec6-9c47-b4d775850842 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90937ff8-d2c6-4ec6-9c47-b4d775850842');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           source      Author  \\\n",
              "78   The Adventures of Tom Sawyer  Mark Twain   \n",
              "68   The Adventures of Tom Sawyer  Mark Twain   \n",
              "172  The Adventures of Tom Sawyer  Mark Twain   \n",
              "\n",
              "                                                  text  n_tokens  \\\n",
              "78   and stop.” “Yes, I’ve heard about that,” said ...      1301   \n",
              "68   Indian; yelling, laughing, chasing boys, jumpi...      1242   \n",
              "172  laugh at this pleasant joke. But the silence w...      1242   \n",
              "\n",
              "                                             embedding  similarity  \n",
              "78   [0.002508266130462289, -0.0182208102196455, 0....    0.860843  \n",
              "68   [-0.026282379403710365, -0.02262263558804989, ...    0.858555  \n",
              "172  [-0.006196146830916405, -0.011552021838724613,...    0.858206  "
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"How did Tom meet Huck for the first time ?\"\n",
        "prompt_embedding = get_embedding(prompt, engine=embedding_model)\n",
        "# find the most relevant parts of the video transcript to the query\n",
        "df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, prompt_embedding))\n",
        "results = (df.sort_values(\"similarity\", ascending=False))\n",
        "results.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtYqNaMskIP3",
        "outputId": "1ad9ece9-a6bb-440c-b7b7-0b4cbbc89f96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4004"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "messages.append({\"role\": \"user\", \"content\": prepare_prompt(prompt, results)})\n",
        "len(encoding.encode(''.join(str(message) for message in messages)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNVN9KgnMNke",
        "outputId": "6bd9132d-80af-43a2-a9f6-a6804f46510d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'system',\n",
              " 'content': '\\nYou are a modern American literature tutor bot. You help students with their study of Mark Twain\\'s Adventures of Tom Sawyer. \\nYou are not an AI language model.\\nYou must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\\n- ALWAYS REPLY IN FRIENDLY YET KNOWLEDGE TONE.\\n- NEVER ANSWER UNLESS YOU HAVE A REFREENCE FROM THE TOM SAYWER NOVEL TO YOUR ANSWER.\\n- IF YOU DON\\'T KNOW ANSWER \\'I DO NOT KNOW\\'.\\nBegin the conversation with a warm greetings, if the user is stresseful or agressive, show understanding and empathy.\\nAt the end of the conversation, respond with \"<|DONE|>\".'}"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8dXDp1ltNL91",
        "outputId": "77559872-b83e-4a0e-c67d-cb1b12085240"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The novel does not provide a clear answer on how Tom met Huck for the first time.'"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = answer(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zf4z3rKjuSA"
      },
      "source": [
        "Nice answer this time too, less creativity and more precisenss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GXkPTAjRfUn",
        "outputId": "4dbee041-af4a-41a8-8559-4929353ba0e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'messages = [{\"role\": \"system\", \"content\": system},]\\nmessages.append({\"role\": \"user\", \"content\": prepare_prompt(prompt, results)})\\nlen(encoding.encode(\\'\\'.join(str(message) for message in messages)))\\n'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "messages.append({\"role\": \"user\", \"content\": prepare_prompt(prompt, results)})\n",
        "len(encoding.encode(''.join(str(message) for message in messages)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p_Xr80IRfUo",
        "outputId": "92a54341-cf99-439a-a147-fcbc2fb25ae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'system',\n",
              " 'content': '\\nYou are a modern American literature tutor bot. You help students with their study of Mark Twain\\'s Adventures of Tom Sawyer. \\nYou are not an AI language model.\\nYou must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\\n- ALWAYS REPLY IN FRIENDLY YET KNOWLEDGE TONE.\\n- NEVER ANSWER UNLESS YOU HAVE A REFREENCE FROM THE TOM SAYWER NOVEL TO YOUR ANSWER.\\n- IF YOU DON\\'T KNOW ANSWER \\'I DO NOT KNOW\\'.\\nBegin the conversation with a warm greetings, if the user is stresseful or agressive, show understanding and empathy.\\nAt the end of the conversation, respond with \"<|DONE|>\".'}"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implement Evaluation Data Generation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4 : Prompt Testing and Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tr1p-GeFqEOC",
        "Ao_wX6r7qEBh",
        "t3ZQOWV9P6B-",
        "W55mIReEPkAI",
        "XjHRfCAUP1vS",
        "G3fjwJuhVw_T",
        "_3jLplz2DPZk",
        "JIN5AkaaQqSG",
        "a8hsGy_xRfUn",
        "xQNtkqjcIdB1"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
