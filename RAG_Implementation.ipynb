{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "install all the required libraries and packes that are use ful for the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anyio in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: certifi in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: click in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: distro in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: h11 in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: httpcore in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.0.2)\n",
            "Requirement already satisfied: httpx in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.26.0)\n",
            "Requirement already satisfied: idna in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: joblib in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: nltk in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.8.1)\n",
            "Requirement already satisfied: numpy in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.26.2)\n",
            "Requirement already satisfied: openai in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: pydantic in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.5.3)\n",
            "Requirement already satisfied: python-dotenv in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.0.0)\n",
            "Requirement already satisfied: regex in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (2023.12.25)\n",
            "Requirement already satisfied: scikit-learn in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (1.3.2)\n",
            "Requirement already satisfied: scipy in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.11.4)\n",
            "Requirement already satisfied: sniffio in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (4.66.1)\n",
            "Requirement already satisfied: typing_extensions in /home/alex/anaconda3/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 13)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /home/alex/anaconda3/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 13)) (2.14.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "system = \"\"\"\n",
        "You are a modern American literature tutor bot. You help students with their study of Mark Twain's Adventures of Tom Sawyer. \n",
        "You are not an AI language model.\n",
        "You must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\n",
        "- ALWAYS REPLY IN A FRIENDLY YET KNOWLEDGEABLE TONE.\n",
        "- NEVER ANSWER UNLESS YOU HAVE A REFERENCE FROM THE TOM SAYWER NOVEL TO YOUR ANSWER.\n",
        "- IF YOU DON'T KNOW ANSWER 'I DO NOT KNOW'.\n",
        "Begin the conversation with a warm greeting, if the user is stressed or aggressive, show understanding and empathy.\n",
        "At the end of the conversation, respond with \"<|DONE|>\".\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING! api_key is not default parameter.\n",
            "                    api_key was transferred to model_kwargs.\n",
            "                    Please confirm that api_key is what you intended.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import ChatCompletion\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "# Set the API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get the API key from the environment variable\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the chat model\n",
        "chat = ChatOpenAI(\n",
        "    model='gpt-3.5-turbo',\n",
        "    api_key=api_key\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7FslLDlSJMo"
      },
      "source": [
        "#### Reinitialzing messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
        "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/alex/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"String theory is a theoretical framework in physics that aims to describe the fundamental structure of the universe. It suggests that elementary particles, such as electrons and quarks, are not point-like entities, but rather tiny, vibrating strings or loops of energy.\\n\\nHere are some key points about string theory:\\n\\n1. Fundamental particles: In string theory, particles are not considered as isolated points, but rather as tiny strings or loops undergoing different vibrations. Each vibration pattern represents a different particle with specific properties, such as mass and charge.\\n\\n2. Extra dimensions: String theory suggests that the universe has more than the three spatial dimensions (length, width, and height) we are familiar with. It postulates that there may be additional compactified dimensions, curled up and too small to be directly observed. These extra dimensions are needed to mathematically reconcile quantum mechanics with gravity.\\n\\n3. Unification of forces: String theory attempts to unify the fundamental forces of nature, namely gravity, electromagnetism, and the strong and weak nuclear forces. By incorporating all these forces into a single framework, it aims to provide a more comprehensive understanding of the universe at its most fundamental level.\\n\\n4. String theory variants: There are different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. These variants differ in the number of dimensions, the types of strings, and the symmetries they possess.\\n\\n5. Challenges and ongoing research: Despite its potential, string theory is still a subject of active research and debate. There are several challenges, including the lack of experimental evidence and the difficulty of making testable predictions. However, string theory has also led to significant advancements in mathematics and theoretical physics.\\n\\nIt's important to note that string theory is a complex and mathematically intensive subject, requiring a strong background in physics and mathematics to fully understand. This overview provides a general introduction, but delving deeper into the topic would require more specialized study.\")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = chat(messages)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add latest AI response to messages\n",
        "messages.append(res)\n",
        "\n",
        "# now create a new user prompt\n",
        "prompt = HumanMessage(\n",
        "    content=\"What is so special about Llama 2?\"\n",
        ")\n",
        "# add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# send to OpenAI\n",
        "res = chat(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4243p0A0G5B"
      },
      "source": [
        "Impressive! the bot persona is effective, and it avoids expressing personal opinions yet it adequately explains the controversy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4243p0A0G5B"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar their contents. \n",
        "First, we break up the novel document into \"sections\" of context, which can be searched and retrieved separately.\n",
        "\n",
        "Sections should be large enough to contain enough information to answer a question; but small enough to fit one or several into the GPT-3 prompt. I found a 200-word text is a good length.\n",
        "so in this data preprocessing we follow:\n",
        "- chunk the data\n",
        "- embed the data\n",
        "- index the data\n",
        "\n",
        " After this I by contexualizing, and guide the LLMs to know more about my prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/7c/cc/8b822be150323492e1d3c2ae46ccd99ddc9841894afdc41c408ffd68918e/chromadb-0.4.22-py3-none-any.whl.metadata\n",
            "  Downloading chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Obtaining dependency information for build>=1.0.3 from https://files.pythonhosted.org/packages/93/dd/b464b728b866aaa62785a609e0dd8c72201d62c5f7c53e7c20f4dceb085f/build-1.0.3-py3-none-any.whl.metadata\n",
            "  Downloading build-1.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: requests>=2.28 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (2.5.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/48/0e/068b658a547d6090b969014146321e28dae1411da54b76d081e51a2af22b/chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Obtaining dependency information for fastapi>=0.95.2 from https://files.pythonhosted.org/packages/e5/80/ddbf524c6169072ab5e8dd4e106d4eb482bf920da1996dde9f308f90aa8c/fastapi-0.109.0-py3-none-any.whl.metadata\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/81/d1/90d8a1c0de615eb849ff0cf5cc5dfbad0e360a8bf0f5f2d41dc54260bfce/uvicorn-0.26.0-py3-none-any.whl.metadata\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (1.26.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/e3/7a/5fd882a002c0b178d9007a79cf65cd939963567dc084877de4bd2794d766/posthog-3.3.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading posthog-3.3.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/11/00/de181c46213b1a5db1fb51468146d54d9dd5a15f8db05a246133a71e16a6/pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/8a/12/ddbf34a866fd0022883bc14cbec3aa2429d54783fa0c90f1fcbc14206249/onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/fc/2e/a8509051aa446783e24ee03d74bd268c07d5d25a8d48686cfcf3429d5d32/opentelemetry_api-1.22.0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/88/76/9057dce1afb24204cbe7f1c04629980f7b0f9aa5f5114c39d2e25f24209a/opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/1d/51/429d04b8694fec2f87184ced4beeab1dd6db194a9444b0a6fca1675338b2/opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/ff/94/588f49e0dd9a62ec46102736d2378330032a55e19c79ff7e4febea7ebed1/opentelemetry_sdk-1.22.0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (0.13.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m234.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m623.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl.metadata\n",
            "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/de/01/a8d9bcc59526f22b8fef29c234cc63434f05dae1154d979222c02b31a557/grpcio-1.60.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading grpcio-1.60.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/42/9d/a88027b5a8752f4b1831d957470f48e23cebc112aaf762880f3adbfba9cf/bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m964.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/6f/34/164e57fec8a9693d7e6ae2d1a345482020ea9e9b32eab95a90bb3eaea83d/kubernetes-29.0.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb)\n",
            "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Obtaining dependency information for mmh3>=4.0.1 from https://files.pythonhosted.org/packages/6f/a4/7ba4bcc838818bcf018e26d118d5ddb605c23c4fad040dc4d811f1cfcb04/mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging>=19.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting starlette<0.36.0,>=0.35.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Obtaining dependency information for starlette<0.36.0,>=0.35.0 from https://files.pythonhosted.org/packages/03/13/c60c738da2fb69d60ee1dc5631e8d152352003cc0bc4ce39582bdd90e293/starlette-0.35.1-py3-none-any.whl.metadata\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /home/alex/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /home/alex/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for google-auth>=1.0.1 from https://files.pythonhosted.org/packages/aa/42/c3873f5a4369d28eb0006bfc80837f28b18bd4e04526f55cc9c8eac7a803/google_auth-2.26.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading google_auth-2.26.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /home/alex/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m223.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/81/9e/63501b8d5b4e40c7260049836bd15ec3270c936e83bc57b85e4603cc212c/protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: sympy in /home/alex/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
            "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/f0/43/c9d8f75ddf08e2a0a27db243c13a700c3cc7ec615b545b697cf6f715ad92/googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.22.0 from https://files.pythonhosted.org/packages/ee/75/0972205c139695ff3b21a58063e0e0440a81eaa2c5dd6ef4c1f22f58fdd5/opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-proto==1.22.0 from https://files.pythonhosted.org/packages/c7/0d/579c664af2f1faca957c3d8c9159ae9fc7a1fe8de7b40a2d2e4fa1832574/opentelemetry_proto-1.22.0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.43b0 from https://files.pythonhosted.org/packages/71/cd/a0456c8e4441d9ef5b412a3ffdf97629a81adeb331f8bb645df4f9153dd8/opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-instrumentation==0.43b0 from https://files.pythonhosted.org/packages/91/f0/4a9f7cbcc697273d847040a9e4f98ceb07b642e1fe5fed56a0fb6b567665/opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-semantic-conventions==0.43b0 from https://files.pythonhosted.org/packages/e0/26/69be0f1a56a362c68fa0c7632d841b1b8f29d809bc6b1b897387c9f46973/opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Obtaining dependency information for opentelemetry-util-http==0.43b0 from https://files.pythonhosted.org/packages/74/91/a87a59baeeb917a93f2cc86fa670cf533328d18a2d09b0cef4f65e8b83e9/opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata\n",
            "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Obtaining dependency information for asgiref~=3.0 from https://files.pythonhosted.org/packages/9b/80/b9051a4a07ad231558fcd8ffc89232711b4e618c15cb7a392a17384bbeef/asgiref-3.7.2-py3-none-any.whl.metadata\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /home/alex/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /home/alex/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/59/23/047a89e66045232fb82c50ae57699e40f70e073ae5ccd53f54e532fbd2a2/httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /home/alex/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for uvloop!=0.15.0,!=0.15.1,>=0.14.0 from https://files.pythonhosted.org/packages/86/cc/1829b3f740e4cb1baefff8240a1c6fc8db9e3caac7b93169aec7d4386069/uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/35/e0/e8a9c1fe30e98c5b3507ad381abc4d9ee2c3b9c0ae62ffe9c164a5838186/watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Obtaining dependency information for websockets>=10.4 from https://files.pythonhosted.org/packages/e3/05/f52a60b66d9faf07a4f7d71dc056bffafe36a7e98c4eb5b78f04fe6e4e85/websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
            "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/alex/anaconda3/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /home/alex/anaconda3/lib/python3.11/site-packages (from starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (4.2.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/alex/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/alex/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/alex/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
            "Downloading chromadb-0.4.22-py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading build-1.0.3-py3-none-any.whl (18 kB)\n",
            "Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m813.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m50.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.60.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m318.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hUsing cached opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
            "Using cached opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
            "Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n",
            "Using cached opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
            "Downloading posthog-3.3.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
            "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.5/186.5 kB\u001b[0m \u001b[31m993.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
            "Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.5/318.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m236.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m63.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m806.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m536.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m39.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=0553cb81108626ce53ae1601294317a60260b5e64805b7aea5c02fe1afd19530\n",
            "  Stored in directory: /home/alex/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, websockets, uvloop, uvicorn, typer, tenacity, rsa, pyproject_hooks, pulsar-client, protobuf, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, importlib-resources, humanfriendly, httptools, grpcio, deprecated, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, googleapis-common-protos, google-auth, coloredlogs, build, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.2.2\n",
            "    Uninstalling tenacity-8.2.2:\n",
            "      Successfully uninstalled tenacity-8.2.2\n",
            "  Attempting uninstall: bcrypt\n",
            "    Found existing installation: bcrypt 3.2.0\n",
            "    Uninstalling bcrypt-3.2.0:\n",
            "      Successfully uninstalled bcrypt-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ragas 0.0.22 requires openai>1, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 build-1.0.3 cachetools-5.3.2 chroma-hnswlib-0.7.3 chromadb-0.4.22 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.109.0 flatbuffers-23.5.26 google-auth-2.26.2 googleapis-common-protos-1.62.0 grpcio-1.60.0 httptools-0.6.1 humanfriendly-10.0 importlib-resources-6.1.1 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.16.3 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-grpc-1.22.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentelemetry-util-http-0.43b0 posthog-3.3.2 protobuf-4.25.2 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 requests-oauthlib-1.3.1 rsa-4.9 starlette-0.35.1 tenacity-8.2.3 typer-0.9.0 uvicorn-0.26.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Design and Develop the Prompt Generation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Prompt Generation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alex\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "C:\\Users\\alex\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:14<00:00, 5.72MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few chunks:\n",
            "['\\ufeffThe Project Gutenberg eBook of The Adventures of Tom Sawyer , by Mark Twain This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever . You may copy it , give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org . If you are not located in the United States , you will have to check the laws of the country where you are located before using this eBook . Title : The Adventures of Tom Sawyer Author : Mark Twain ( Samuel Clemens ) Release Date : July , 1993 [ eBook # 74 ] [ Most recently updated : March 29 , 2021 ] Language : English Character set encoding : UTF-8 Produced by : David Widger * * * START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF TOM SAWYER * * * THE ADVENTURES OF TOM SAWYER By Mark Twain ( Samuel Langhorne Clemens ) CONTENTS CHAPTER I. Y-o-u-u Tom-Aunt Polly Decides Upon her Duty—Tom Practices Music—The Challenge—A Private Entrance CHAPTER II . Strong Temptations—Strategic', 'Movements—The Innocents Beguiled CHAPTER III . Tom as a General—Triumph and Reward—Dismal Felicity—Commission and Omission CHAPTER IV . Mental Acrobatics—Attending Sunday—School—The Superintendent— “ Showing off ” —Tom Lionized CHAPTER V. A Useful Minister—In Church—The Climax CHAPTER VI . Self-Examination—Dentistry—The Midnight Charm—Witches and Devils—Cautious Approaches—Happy Hours CHAPTER VII . A Treaty Entered Into—Early Lessons—A Mistake Made CHAPTER VIII . Tom Decides on his Course—Old Scenes Re-enacted CHAPTER IX . A Solemn Situation—Grave Subjects Introduced—Injun Joe Explains CHAPTER X . The Solemn Oath—Terror Brings Repentance—Mental Punishment CHAPTER XI . Muff Potter Comes Himself—Tom ’ s Conscience at Work CHAPTER XII . Tom Shows his Generosity—Aunt Polly Weakens CHAPTER XIII . The Young Pirates—Going to the Rendezvous—The Camp—Fire Talk CHAPTER XIV . Camp-Life—A Sensation—Tom Steals Away from Camp CHAPTER XV . Tom Reconnoiters—Learns the Situation—Reports at Camp CHAPTER XVI . A Day ’ s Amusements—Tom Reveals a Secret—The Pirates take a Lesson—A Night Surprise—An Indian War CHAPTER XVII . Memories of the Lost Heroes—The Point in Tom ’ s Secret CHAPTER XVIII . Tom ’ s Feelings Investigated—Wonderful Dream—Becky Thatcher Overshadowed—Tom Becomes Jealous—Black Revenge CHAPTER XIX . Tom Tells the Truth CHAPTER XX . Becky in a Dilemma—Tom ’ s Nobility Asserts Itself', 'CHAPTER XXI . Youthful Eloquence—Compositions by the Young Ladies—A Lengthy Vision—The Boy ’ s Vengeance Satisfied CHAPTER XXII . Tom ’ s Confidence Betrayed—Expects Signal Punishment CHAPTER XXIII . Old Muff ’ s Friends—Muff Potter in Court—Muff Potter Saved CHAPTER XXIV . Tom as the Village Hero—Days of Splendor and Nights of Horror—Pursuit of Injun Joe CHAPTER XXV . About Kings and Diamonds—Search for the Treasure—Dead People and Ghosts CHAPTER XXVI . The Haunted House—Sleepy Ghosts—A Box of Gold—Bitter Luck CHAPTER XXVII . Doubts to be Settled—The Young Detectives CHAPTER XXVIII . An Attempt at No . Two—Huck Mounts Guard CHAPTER XXIX . The Pic-nic—Huck on Injun Joe ’ s Track—The “ Revenge ” Job—Aid for the Widow CHAPTER XXX . The Welshman Reports—Huck Under Fire—The Story Circulated —A New Sensation—Hope Giving Way to Despair CHAPTER XXXI . An Exploring Expedition—Trouble Commences—Lost in the Cave—Total Darkness—Found but not Saved CHAPTER XXXII . Tom tells the Story of their Escape—Tom ’ s Enemy in Safe Quarters CHAPTER XXXIII . The Fate of Injun Joe—Huck and Tom Compare Notes —An Expedition to the Cave—Protection Against Ghosts— “ An Awful Snug Place ” —A Reception at the Widow Douglas ’ s CHAPTER XXXIV', '. Springing a Secret—Mr . Jones ’ Surprise a Failure CHAPTER XXXV . A New Order of Things—Poor Huck—New Adventures Planned ILLUSTRATIONS Tom Sawyer Tom at Home Aunt Polly Beguiled A Good Opportunity Who ’ s Afraid Late Home Jim ’ Tendin ’ to Business Ain ’ t that Work ? Cat and Toys Amusement Becky Thatcher Paying Off After the Battle “ Showing Off ” Not Amiss Mary Tom Contemplating Dampened Ardor Youth Boyhood Using the “ Barlow ” The Church Necessities Tom as a Sunday-School Hero The Prize At Church The Model Boy The Church Choir A Side Show Result of Playing in Church The Pinch-Bug Sid Dentistry Huckleberry Finn Mother Hopkins Result of Tom ’ s Truthfulness Tom as an Artist Interrupted Courtship The Master Vain Pleading Tail Piece The Grave in the Woods Tom Meditates Robin Hood and his Foe Death of Robin Hood Midnight Tom ’ s Mode of Egress Tom ’ s Effort at Prayer Muff Potter Outwitted The Graveyard Forewarnings Disturbing Muff ’ s Sleep Tom ’ s Talk with his Aunt Muff Potter A Suspicious Incident Injun Joe ’ s two Victims In the Coils Peter Aunt Polly seeks Information A General', 'Good Time Demoralized Joe Harper On Board Their First Prize The Pirates Ashore Wild Life The Pirate ’ s Bath The Pleasant Stroll The Search for the Drowned The Mysterious Writing River View What Tom Saw Tom Swims the River Taking Lessons The Pirates ’ Egg Market Tom Looking for Joe ’ s Knife The Thunder Storm Terrible Slaughter The Mourner Tom ’ s Proudest Moment Amy Lawrence Tom tries to Remember The Hero A Flirtation Becky Retaliates A Sudden Frost Counter-irritation Aunt Polly Tom justified The Discovery Caught in the Act Tom Astonishes the School Literature Tom Declaims Examination Evening On Exhibition Prize Authors The Master ’ s Dilemma The School House The Cadet Happy for Two Days Enjoying the Vacation The Stolen Melons The Judge Visiting the Prisoner Tom Swears The Court Room The Detective Tom Dreams The Treasure The Private Conference A King ; Poor Fellow ! Business The Ha ’ nted House Injun Joe The Greatest and Best Hidden Treasures Unearthed The Boy ’ s Salvation Room No . 2 The Next Day ’ s Conference Treasures Uncle Jake Buck at Home The Haunted Room “ Run for Your Life ” McDougal ’ s Cave Inside']\n",
            "Number of documents in the collection: 461\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from dotenv import load_dotenv\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Get or create a collection\n",
        "collection = chroma_client.get_or_create_collection(name=\"my_collection\")\n",
        "\n",
        "# Define the chunk size\n",
        "chunk_size = 200\n",
        "\n",
        "# Read the data from the file\n",
        "with open(\"c:/users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split text into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Tokenize each sentence into words\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Flatten the list of sentences into a list of words\n",
        "flat_tokens = [token for sentence_tokens in tokenized_sentences for token in sentence_tokens]\n",
        "\n",
        "# Chunk the tokens\n",
        "chunks = [' '.join(flat_tokens[i:i+chunk_size]) for i in range(0, len(flat_tokens), chunk_size)]\n",
        "\n",
        "# Add chunks to the collection\n",
        "collection.add(documents=chunks, ids=[str(id) for id in range(len(chunks))])\n",
        "\n",
        "# Print the first few chunks\n",
        "print(\"First few chunks:\")\n",
        "print(chunks[:5])\n",
        "\n",
        "# Check the count of documents in the collection\n",
        "num_documents = collection.count()\n",
        "\n",
        "# Print the number of documents\n",
        "print(f\"Number of documents in the collection: {num_documents}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# embedding model parameters\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
        "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Add of existing embedding ID: prompt_1\n",
            "Insert of existing embedding ID: prompt_1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "objective = \"Summarize the Adventures of Tom Sawyer\"\n",
        "scenarios = [\n",
        "    (\"Describe Tom's first encounter with Huckleberry Finn\", \"Tom helps Huck escape from his abusive father.\"),\n",
        "    (\"Explain the relationship between Tom and Becky\", \"They become romantically involved and share adventures.\"),\n",
        "    (\"Detail the events at the graveyard\", \"Tom and Huck witness Injun Joe murder Dr. Robinson.\"),\n",
        "]\n",
        "\n",
        "generated_prompt = generate_prompt(objective, scenarios)\n",
        "\n",
        "# Generate an ID for the generated prompt\n",
        "id = \"prompt_1\"\n",
        "\n",
        "# Store the generated prompt in the collection\n",
        "collection.add(documents=[generated_prompt], ids=[id])\n",
        "\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n",
            "\n",
            "Similarity Score with User Input Description: 0.2735395227375971\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "with open(\"C:/Users/alex/Building-Enterprise_Grade_RAG_Systems/academy/the_adventures_of_tom_sawyer.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into chunks of 200 words\n",
        "words = text.split()\n",
        "sections = [' '.join(words[i:i+200]) for i in range(0, len(words), 200)]\n",
        "\n",
        "# Convert paragraphs into a Pandas DataFrame\n",
        "df = pd.DataFrame({\"sections\": sections})\n",
        "\n",
        "def generate_prompt(objective, scenarios):\n",
        "    template = \"Objective: {}\\n\\nScenarios:\\n{}\"\n",
        "    scenario_template = \"{}. {}\\n   - Expected Output: {}\\n\"\n",
        "    \n",
        "    prompt = template.format(objective, ''.join([scenario_template.format(i+1, scenario, output) for i, (scenario, output) in enumerate(scenarios)]))\n",
        "    return prompt\n",
        "\n",
        "def calculate_similarity(prompt, input_description):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([prompt, input_description])\n",
        "    similarity_score = cosine_similarity(vectors)[0, 1]\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "objective = \"Summarize the Adventures of Tom Sawyer\"\n",
        "scenarios = [\n",
        "    (\"Describe Tom's first encounter with Huckleberry Finn\", \"Tom helps Huck escape from his abusive father.\"),\n",
        "    (\"Explain the relationship between Tom and Becky\", \"They become romantically involved and share adventures.\"),\n",
        "    (\"Detail the events at the graveyard\", \"Tom and Huck witness Injun Joe murder Dr. Robinson.\"),\n",
        "]\n",
        "\n",
        "generated_prompt = generate_prompt(objective, scenarios)\n",
        "\n",
        "# User-provided input description\n",
        "user_input_description = \"Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\"\n",
        "\n",
        "# Calculate similarity between generated prompt and user input description\n",
        "similarity_score = calculate_similarity(generated_prompt, user_input_description)\n",
        "\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n",
        "print(\"\\nSimilarity Score with User Input Description:\", similarity_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FJd2Fb9DAfCt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    ﻿The Project Gutenberg eBook of The Adventures...\n",
              "1    CHAPTER VI. Self-Examination—Dentistry—The Mid...\n",
              "2    The Haunted House—Sleepy Ghosts—A Box of Gold—...\n",
              "3    Pinch-Bug Sid Dentistry Huckleberry Finn Mothe...\n",
              "4    the Prisoner Tom Swears The Court Room The Det...\n",
              "Name: sections, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sections[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Prompt Evalaution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W55mIReEPkAI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Prompt:\n",
            "Objective: Summarize the Adventures of Tom Sawyer\n",
            "\n",
            "Scenarios:\n",
            "1. Describe Tom's first encounter with Huckleberry Finn\n",
            "   - Expected Output: Tom helps Huck escape from his abusive father.\n",
            "2. Explain the relationship between Tom and Becky\n",
            "   - Expected Output: They become romantically involved and share adventures.\n",
            "3. Detail the events at the graveyard\n",
            "   - Expected Output: Tom and Huck witness Injun Joe murder Dr. Robinson.\n",
            "\n",
            "\n",
            "User Input Description:\n",
            "Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\n",
            "\n",
            "Similarity Score with User Input Description: 0.2735395227375971\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def evaluate_prompt(prompt, user_input_description):\n",
        "    \"\"\"\n",
        "    Evaluate the similarity between a generated prompt and a user-provided input description.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The generated prompt.\n",
        "    - user_input_description (str): The user-provided input description.\n",
        "\n",
        "    Returns:\n",
        "    - float: Similarity score between the prompt and user input description.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([prompt, user_input_description])\n",
        "    similarity_score = cosine_similarity(vectors)[0, 1]\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "user_input_description = \"Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\"\n",
        "\n",
        "# Load the generated prompt from the file\n",
        "with open(\"generated_prompt.txt\", \"r\") as generated_prompt_file:\n",
        "    generated_prompt = generated_prompt_file.read()\n",
        "\n",
        "# Evaluate the generated prompt\n",
        "similarity_score = evaluate_prompt(generated_prompt, user_input_description)\n",
        "\n",
        "# Display results\n",
        "print(\"Generated Prompt:\")\n",
        "print(generated_prompt)\n",
        "print(\"\\nUser Input Description:\")\n",
        "print(user_input_description)\n",
        "print(\"\\nSimilarity Score with User Input Description:\", similarity_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W55mIReEPkAI"
      },
      "source": [
        "#### Prepre Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XjHRfCAUP1vS"
      },
      "outputs": [],
      "source": [
        "def prepare_prompt(prompt, results):\n",
        "  tokens_limit = 4096 # Limit for gpt-3.5-turbo\n",
        "  # build our prompt with the retrieved contexts included\n",
        "  user_start = (\n",
        "      \"Answer the question based on the context below.\\n\\n\"+\n",
        "      \"Context:\\n\"\n",
        "  )\n",
        "\n",
        "  user_end = (\n",
        "      f\"\\n\\nQuestion: {prompt}\\nAnswer:\"\n",
        "  )\n",
        "\n",
        "  count_of_tokens_consumed = len(encoding.encode(\"\\\"role\\\":\\\"system\\\"\" + \", \\\"content\\\" :\\\"\" + system\n",
        "                                            + user_start + \"\\n\\n---\\n\\n\" + user_end))\n",
        "\n",
        "  count_of_tokens_for_context = tokens_limit - count_of_tokens_consumed\n",
        "\n",
        "  contexts =\"\"\n",
        "  # Fill in context as long as within limit\n",
        "  for i in range(len(results)):\n",
        "    if (count_of_tokens_for_context>=results.n_tokens.iloc[i]):\n",
        "        contexts += results.text.iloc[i] + \"\\n\"\n",
        "        count_of_tokens_for_context -=1\n",
        "        count_of_tokens_for_context -= results.n_tokens.iloc[i]\n",
        "\n",
        "  complete_prompt = user_start + contexts + \"\\n\\n---\\n\\n\" + user_end\n",
        "  return complete_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjHRfCAUP1vS"
      },
      "source": [
        "#### Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "G3fjwJuhVw_T"
      },
      "outputs": [],
      "source": [
        "def answer(messages):\n",
        "  response = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=messages,\n",
        "              temperature=0\n",
        "          )\n",
        "  return response[\"choices\"][0][\"message\"][\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PXfoLRhiYUp"
      },
      "source": [
        "The model is more precise but the treasure was counted at the end of chapter 34, not 34 or XXXV, actually in the last paragraph in chapter 34, I wonder if this confused the model to think it was chapter 35!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3Zf4z3rKjuSA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hello! Welcome to your modern American literature tutoring session. I'm here to help you with your study of Mark Twain's Adventures of Tom Sawyer. How can I assist you today?\""
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = answer(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zf4z3rKjuSA"
      },
      "source": [
        "Nice answer this time too, less creativity and more precisenss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Implement Evaluation Data Generation and Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_cases_and_evaluate(user_input_description):\n",
        "    # Initialize the chat model\n",
        "    chat = ChatOpenAI(model='gpt-3.5-turbo', api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    # Generate diverse test cases\n",
        "    test_cases = [\n",
        "        \"Generate a summary of Tom Sawyer's adventures.\",\n",
        "        \"Describe the main characters in Tom Sawyer's story.\",\n",
        "        \"Explore the themes of friendship in Tom Sawyer's adventures.\"\n",
        "    ]\n",
        "\n",
        "    # Evaluate each test case\n",
        "    evaluation_results = []\n",
        "\n",
        "    for test_case in test_cases:\n",
        "        # Make an API call to OpenAI to get the model's response\n",
        "        response = chat.generate([{\"content\": f\"user: {test_case}\"}])\n",
        "\n",
        "        # Evaluate similarity between the generated prompt and user input description\n",
        "        similarity_score = evaluate_similarity(response['choices'][0]['message']['content'], user_input_description)\n",
        "\n",
        "        # Store evaluation results\n",
        "        evaluation_results.append({\n",
        "            \"generated_prompt\": response['choices'][0]['message']['content'],\n",
        "            \"user_input_description\": user_input_description,\n",
        "            \"similarity_score\": similarity_score\n",
        "        })\n",
        "\n",
        "    # Store evaluation results in ChromaDB\n",
        "    evaluation_collection.insert(evaluation_results)\n",
        "\n",
        "    return evaluation_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents in the collection: 461\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of documents in the collection: {num_documents}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 29 (918715928.py, line 32)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[43], line 32\u001b[1;36m\u001b[0m\n\u001b[1;33m    def evaluate_similarity(prompt, user_input_description):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 29\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain.chat_models import ChatOpenA\n",
        "import chromadb\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the chat model\n",
        "chat = ChatOpenA(\n",
        "    model='gpt-3.5-turbo',\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "# Initialize ChromaDB client\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Name of the collection for storing evaluation results\n",
        "evaluation_collection_name = \"evaluation_results\"\n",
        "\n",
        "# Try to get the evaluation results collection, and create it if it doesn't exist\n",
        "if not chroma_client.has_collection(name=evaluation_collection_name):\n",
        "    chroma_client.create_collection(name=evaluation_collection_name)\n",
        "\n",
        "# Get the evaluation results collection\n",
        "evaluation_collection = chroma_client.get_collection(name=evaluation_collection_name)\n",
        "\n",
        "def generate_test_cases_and_evaluate(user_input_description):\n",
        "    # ... (same as before)\n",
        "\n",
        "def evaluate_similarity(prompt, user_input_description):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([prompt, user_input_description])\n",
        "    similarity_score = cosine_similarity(vectors)[0, 1]\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "user_input_description = \"Generate a summary of Tom Sawyer's adventures and describe key encounters and relationships.\"\n",
        "\n",
        "# Generate test cases and evaluate\n",
        "evaluation_results = generate_test_cases_and_evaluate(user_input_description)\n",
        "\n",
        "# Display results\n",
        "for result in evaluation_results:\n",
        "    print(\"\\nGenerated Prompt:\")\n",
        "    print(result[\"generated_prompt\"])\n",
        "    print(\"\\nSimilarity Score with User Input Description:\", result[\"similarity_score\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4 : Prompt Testing and Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tr1p-GeFqEOC",
        "Ao_wX6r7qEBh",
        "t3ZQOWV9P6B-",
        "W55mIReEPkAI",
        "XjHRfCAUP1vS",
        "G3fjwJuhVw_T",
        "_3jLplz2DPZk",
        "JIN5AkaaQqSG",
        "a8hsGy_xRfUn",
        "xQNtkqjcIdB1"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
